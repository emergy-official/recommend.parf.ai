{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./output/content_based_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/embeddings_dict.pkl', 'rb') as f:\n",
    "   embeddings_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrames from disk\n",
    "user_profiles_df_all = pd.read_pickle(\"./output/user_profiles_all.pkl\")\n",
    "df_articles = pd.read_pickle(\"./output/df_articles.pkl\")\n",
    "article_embeddings_df = pd.read_pickle(\"./output/articles_embed_df.pkl\")\n",
    "len(user_profiles_df_all[\"user_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_all_articles_scores(user_id, df, df_articles, article_embeddings_df, model):\n",
    "    # Retrieve the user's embedding\n",
    "    user_profile = df[df['user_id'] == user_id].iloc[0]\n",
    "    \n",
    "    if user_profile.empty:\n",
    "        raise ValueError(\"User ID not found in the user profiles.\")\n",
    "\n",
    "    user_embedding = user_profile['user_embedding']\n",
    "\n",
    "    # Get all articles embeddings\n",
    "    embeddings_dict = article_embeddings_df.T.to_dict('list')\n",
    "    \n",
    "    article_ids = list(embeddings_dict.keys())\n",
    "    combined_features_list = [np.concatenate((user_embedding, article_embedding)).reshape(1, -1) \n",
    "                              for article_embedding in embeddings_dict.values()]\n",
    "\n",
    "    all_embeddings = np.vstack(combined_features_list)\n",
    "    print(\"all_embeddings\", all_embeddings.shape)\n",
    "    \n",
    "    # Predict relevance scores using the trained model\n",
    "    scores = model.predict(all_embeddings, verbose=0).flatten()\n",
    "\n",
    "    # Create a dataframe with article IDs, category IDs, and scores\n",
    "    article_scores_df = df_articles[['article_id', 'category_id']].copy()\n",
    "    article_scores_df['score'] = article_scores_df['article_id'].map(dict(zip(article_ids, scores)))\n",
    "    \n",
    "    # Remove any unwanted header rows if present\n",
    "    # article_scores_df.columns = article_scores_df.columns.droplevel(0)\n",
    "    article_scores_df.reset_index(drop=True, inplace=True)\n",
    "    return article_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id=15587\n",
    "articles_scores = infer_all_articles_scores(user_id, user_profiles_df_all, df_articles, article_embeddings_df, model)\n",
    "articles_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profiles_df_all[user_profiles_df_all[\"user_id\"] == 15958]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_scores[articles_scores[\"article_id\"].isin([95680, 300470, 261680, 273397])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dcg(y_true, y_pred, k):\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(1, len(y_true) + 1) + 1)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def compute_ndcg(y_true, y_pred, k):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return 0.0\n",
    "    dcg = compute_dcg(y_true, y_pred, k)\n",
    "    idcg = compute_dcg(y_true, sorted(y_true, reverse=True), k)\n",
    "    return dcg / idcg if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_user_profiles_df = user_profiles_df_all\n",
    "articles_df = df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detailed_ndcg_for_user(user_id, k=10):\n",
    "    user = sampled_user_profiles_df.loc[sampled_user_profiles_df['user_id'] == user_id].iloc[0]\n",
    "    user_embedding = user['user_embedding']\n",
    "    clicked_articles = set(user['click_article_id'])\n",
    "\n",
    "    all_embeddings = []\n",
    "    article_ids = [article_id for article_id in articles_df['article_id'] if article_id in embeddings_dict]\n",
    "    all_embeddings = [np.concatenate((user_embedding, embeddings_dict[article_id])).reshape(1, -1) for article_id in article_ids]\n",
    "    \n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    print(\"all_embeddings\", all_embeddings.shape)\n",
    "    scores = model.predict(all_embeddings, verbose=0).flatten()\n",
    "    \n",
    "    true_labels = np.array([1 if article_id in clicked_articles else 0 for article_id in article_ids])\n",
    "    \n",
    "    order = np.argsort(scores)[::-1][:k]\n",
    "    ranked_article_ids = np.array(article_ids)[order]\n",
    "    ranked_scores = scores[order]\n",
    "    ranked_true_labels = true_labels[order]\n",
    "    \n",
    "    dcg_score = compute_dcg(ranked_true_labels, ranked_scores, k)\n",
    "    idcg_score = compute_dcg(ranked_true_labels, sorted(ranked_true_labels, reverse=True), k)\n",
    "    ndcg_score = dcg_score / idcg_score if idcg_score > 0 else 0.0\n",
    "    \n",
    "    print(f\"User ID: {user_id}\")\n",
    "\n",
    "    print(\"\\nGround Truth Relevance:\")\n",
    "    for article_id, label in zip(article_ids, true_labels):\n",
    "        if label > 0:\n",
    "            print(f\"  Article {article_id}: Relevance {label}\")\n",
    "    \n",
    "    print(\"\\nTop-{0} Predicted Ranking:\".format(k))\n",
    "    for i, (article_id, score, true_label) in enumerate(zip(ranked_article_ids, ranked_scores, ranked_true_labels)):\n",
    "        print(f\"  Rank {i+1}: Article {article_id} | Predicted Score: {score:.4f} | True Relevance: {true_label}\")\n",
    "    \n",
    "    print(f\"\\nDCG@{k}: {dcg_score:.4f}\")\n",
    "    print(f\"IDCG@{k}: {idcg_score:.4f}\")\n",
    "    print(f\"NDCG@{k}: {ndcg_score:.4f}\")\n",
    "show_detailed_ndcg_for_user(15587, k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
